---
file: /home/pedro/Documents/chatgpt_export/Markdown/New chat (1).md
heading_stack: <root> -> 18e042b6-0753-47b9-8b94-dbf396965d51 -> System -> 705df361-3567-44f4-ad9c-70bb5d82744c -> System -> aaa29996-ddf3-403a-a4bb-fdfc7ef52d1a -> User -> 29be782a-5014-4a86-af90-9005dfcedffd -> Assistant
---
# Assistant

To accomplish this task, we'll proceed with the following steps:

1. Implement the naive version of the `adjust_rgb` function.
2. Implement an optimized version using Python's built-in `functools.lru_cache`.
3. Create a custom version of `lru_cache` that is tolerant to floating-point variations.
4. Benchmark the three different implementations.

Let's start with the naive implementation, which is already provided. Then we'll move on to the `lru_cache` version.

### Naive Implementation

The naive implementation is exactly the function you've provided. We don't need to add anything to it.

### LRU Cached Version

We can use Python's `functools.lru_cache` to cache the results of the `adjust_rgb` function, thereby avoiding redundant calculations for the same input.

Here's how to do it:

[child ⬇️](#1b9602eb-4a57-4178-bdd7-e7b55fca4a3b)

---

(main branch ⎇)
###### 1b9602eb-4a57-4178-bdd7-e7b55fca4a3b
[parent ⬆️](#29be782a-5014-4a86-af90-9005dfcedffd)
